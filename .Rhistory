cbind(select(SEdat, SE_social)) %>%
cbind(select(SEdat, SE_appear)) %>%
cbind(select(Mooddat, Mood_total)) %>%
cbind(select(PDdat, PD_general)) %>%
cbind(select(PDRdat, PD_race)) %>%
cbind(EIdat[,8:11]) %>%
cbind(select(EIdat, EI_total)) %>%
cbind(select(WellBdat, WellB_total)) %>%
cbind(select(WellBdat, WellB_PA)) %>%
cbind(select(WellBdat, WellB_NA)) %>%
cbind(select(WellRdat, WellR_total)) %>%
cbind(select(WellRdat, WellR_auto)) %>%
cbind(select(WellRdat, WellR_envir)) %>%
cbind(select(WellRdat, WellR_accept))
names(datWithTotScores)
write.table(datWithTotScores, file = "datWithCalcScores.txt", sep = "\t", row.names = F)
# Separate into two separate data sets for white participants and minority
dat = read.delim("datWithCalcScores.txt")
latSub = dat[!(is.na(dat$Ethn_1 == 1)),] # 75 Latino
blackSub = dat[!(is.na(dat$Ethn_3 == 1)),] # 187 Black
asianSub = dat[!(is.na(dat$Ethn_4 == 1)),] # 114 Asian
nativeSub = dat[!(is.na(dat$Ethn_5 == 1)),] # 17 Native American
meSub = dat[!(is.na(dat$Ethn_6 == 1)),] # 3 Middle Eastern
otherSub = dat[!(is.na(dat$Ethn_7 == 1)),] # 25 other
whiteSub = dat[!(is.na(dat$Ethn_2 == 1)),] # 165 White subs
# combine non-White subs without double counting people who said more than one
# note: counts people who are mixed (White and something else)
nonWhiteSubs = rbind(latSub, blackSub[!(blackSub$Subject %in% latSub$Subject),])
nonWhiteSubs = rbind(nonWhiteSubs, asianSub[!(asianSub$Subject %in% nonWhiteSubs$Subject),])
nonWhiteSubs = rbind(nonWhiteSubs, nativeSub[!(nativeSub$Subject %in% nonWhiteSubs$Subject),])
nonWhiteSubs = rbind(nonWhiteSubs, meSub[!(meSub$Subject %in% nonWhiteSubs$Subject),])
nrow(nonWhiteSubs) # 377
length(unique(nonWhiteSubs$Subject)) #377
# Examine subjects who said "other"
View(otherSub[,c(134:141,155:170)])
View(otherSub[grep("white", otherSub$Ethn_7_TEXT),c(134:141,155:170)])
# add some to nonWhites
nW = c(92, 152, 175, 258, 348, 371, 411, 437, 496, 511, 535, 539, 561)
nonWhiteSubs = rbind(nonWhiteSubs, otherSub[otherSub$Subject %in% nW & !(otherSub$Subject %in% nonWhiteSubs$Subject),])
# some have no race info at all
noInfo = c(2, 5, 17, 23, 24, 28, 30, 32, 34, 35, 36, 38, 40, 95)
# the rest should be white
WhiteSubs = dat[!(dat$Subject %in% nonWhiteSubs$Subject) & !(dat$Subject %in% noInfo),]
# check to make sure it all adds up
nrow(WhiteSubs) # 142
nrow(nonWhiteSubs) # 389
length(noInfo) # 14
length(unique(dat$Subject)) # it all adds up to 545 subjects
# write files for white subjects and non white subjects
write.table(WhiteSubs, "WhiteSubsWithCalcScores.txt", sep = "\t", row.names = F)
write.table(nonWhiteSubs, "nonWhiteSubsWithCalcScores.txt", sep = "\t", row.names = F)
dat = read.delim("datWithCalcScores.txt")
# UCLA loneliness: 20 items
UCLAtime = dat$T3_3 + dat$T4_3
hist(UCLAtime, breaks = 30)
m1 = mean(UCLAtime, na.rm = T)
s1 = sd(UCLAtime, na.rm = T)
sum(UCLAtime < 20, na.rm = T) # 14 subjects
sum(UCLAtime < (m1-s1), na.rm = T) # 56 subjects
sum(UCLAtime > (m1+3*s1), na.rm = T) # 11 subjects
subs1 = dat$Subject[(dat$T3_3 + dat$T4_3) < (m1-s1)]
subs1 = c(subs1, dat$Subject[(dat$T3_3 + dat$T4_3) > (m1+3*s1)])
# Satisfaction with life: 5 items
SWLStime = dat$T5_3
hist(SWLStime, breaks = 30)
m2 = mean(SWLStime, na.rm = T)
s2 = sd(SWLStime, na.rm = T)
sum(SWLStime < 5, na.rm = T) # 3 subjects
sum(SWLStime < (m2-s2), na.rm = T) # 2 subjects
sum(SWLStime > (m2+3*s2), na.rm = T) # 8 subjects
subs2 = dat$Subject[dat$T5_3 < (m2-s2)]
subs2 = c(subs2, dat$Subject[dat$T5_3 > (m1+3*s1)])
# Self-esteem: 20 items
SEtime = dat$T6_3
hist(SEtime, breaks = 30)
m3 = mean(SEtime, na.rm = T)
s3 = sd(SEtime, na.rm = T)
sum(SEtime < 20, na.rm = T) # 67 subjects
sum(SEtime < (m3-s3), na.rm = T) # 3 subjects
sum(SEtime > (m3+3*s3), na.rm = T) # 11 subjects
subs3 = dat$Subject[dat$T6_3 < (m3-s3)]
subs3 = c(subs3, dat$Subject[dat$T6_3 > (m3+3*s3)])
# Mood: 16 items
Moodtime = dat$T7_3
hist(Moodtime, breaks = 30)
m4 = mean(Moodtime, na.rm = T)
s4 = sd(Moodtime, na.rm = T)
sum(Moodtime < 16, na.rm = T) # 28 subjects
sum(Moodtime < (m4-s4), na.rm = T) # 23 subjects
sum(Moodtime > (m4+3*s4), na.rm = T) # 7 subjects
subs4 = dat$Subject[dat$T7_3 < (m4-s4)]
subs4 = c(subs4, dat$Subject[dat$T7_3 > (m4+3*s4)])
# PD: 9 items
PDtime = dat$T8_3 + dat$T9_3
hist(PDtime, breaks = 30)
m5 = mean(PDtime, na.rm = T)
s5 = sd(PDtime, na.rm = T)
sum(PDtime < 9, na.rm = T) # 0 subjects
sum(PDtime < (m5-s5), na.rm = T) # 19 subjects
sum(PDtime > (m5+3*s5), na.rm = T) # 7 subjects
subs5 = dat$Subject[dat$T8_3 + dat$T9_3 < (m5-s5)]
subs5 = c(subs5, dat$Subject[dat$T8_3 + dat$T9_3 > (m5+3*s5)])
# PDR: 9 items
PDRtime = dat$T10_3 + dat$T11_3
hist(PDRtime, breaks = 30)
m6 = mean(PDRtime, na.rm = T)
s6 = sd(PDRtime, na.rm = T)
sum(PDRtime < 9, na.rm = T) # 1 subjects
sum(PDRtime < (m6-s6), na.rm = T) # 0 subjects
sum(PDRtime > (m6+3*s6), na.rm = T) # 7 subjects
subs6 = dat$Subject[dat$T10_3 + dat$T11_3 < (m6-s6)]
subs6 = c(subs6, dat$Subject[dat$T10_3 + dat$T11_3 > (m6+3*s6)])
# EIS: 9 items
EIStime = dat$T12_3
hist(EIStime, breaks = 30)
m7 = mean(EIStime, na.rm = T)
s7 = sd(EIStime, na.rm = T)
sum(EIStime < 9, na.rm = T) # 10 subjects
sum(EIStime < (m7-s7), na.rm = T) # 1 subjects
sum(EIStime > (m7+3*s7), na.rm = T) # 8 subjects
subs7 = dat$Subject[dat$T12_3 < (m7-s7)]
subs7 = c(subs7, dat$Subject[dat$T12_3 > (m7+3*s7)])
# WellB: 10 items
WellBtime = dat$T13_3
hist(WellBtime, breaks = 30)
m8 = mean(WellBtime, na.rm = T)
s8 = sd(WellBtime, na.rm = T)
sum(WellBtime < 10, na.rm = T) # 14 subjects
sum(WellBtime < (m8-s8), na.rm = T) # 0 subjects
sum(WellBtime > (m8+3*s8), na.rm = T) # 7 subjects
subs8 = dat$Subject[dat$T13_3 < (m8-s8)]
subs8 = c(subs8, dat$Subject[dat$T13_3 > (m8+3*s8)])
# WellR: 10 items
WellRtime = dat$T14_3
hist(WellRtime, breaks = 30)
m9 = mean(WellRtime, na.rm = T)
s9 = sd(WellRtime, na.rm = T)
sum(WellRtime < 10, na.rm = T) # 24 subjects
sum(WellRtime < (m9-s9), na.rm = T) # 2 subjects
sum(WellRtime > (m9+3*s9), na.rm = T) # 8 subjects
subs9 = dat$Subject[dat$T14_3 < (m9-s9)]
subs9 = c(subs9, dat$Subject[dat$T14_3 > (m9+3*s9)])
# total time taken
totalTime = UCLAtime + SWLStime + SEtime + Moodtime + PDtime + PDRtime + EIStime + WellBtime + WellRtime
hist(totalTime, breaks = 30)
badsubs1 = unique(c(subs1, subs2, subs3, subs4, subs5, subs6, subs7, subs8, subs9)) # 115 subjects
#############################################################################################
##################### Attention checks ##########################################
##########################################################################################
# Complete in one sitting (1) or interuppted (2)
a = (dat$Interr == 2)
sum(a, na.rm = T) # 12 subjects
subs10 = dat$Subject[dat$Interr == 2]
# Not distracted (1) or distracted (2)
b = (dat$Distr == 2)
sum(b, na.rm = T) # 21 subjects
subs11 = dat$Subject[dat$Distr == 2]
# Had total privacy (1) or others influenced response (2)
c = (dat$Privacy == 2)
sum(c, na.rm = T) # 4 subjects
subs12 = dat$Subject[dat$Privacy == 2]
# Completed on full size (1) or mobile (2)
sum(dat$Scrn_Size == 2, na.rm = T) # 49 subjects
# People who have answered 1 or more questions with undesirable response
sum(a + b + c == 1, na.rm = T) # 24 subjects
sum(a + b + c == 2, na.rm = T) # 5 subjects
sum(a + b + c == 3, na.rm = T) # 1 subject
subs13 = dat$Subject[(dat$Interr + dat$Distr + dat$Privacy) >= 5] # 3 items + 2 yeses
badsubs2 = unique(c(badsubs1, subs13)) # 116 subjects (only added 1 on top of ones whose time was unacceptable)
nonWhite = read.delim("nonWhiteSubsWithCalcScores.txt")
White = read.delim("WhiteSubsWithCalcScores.txt")
sum(badsubs2 %in% dat$Subject)
noBSall = dat[!(dat$Subject %in% badsubs2),]
noBSwhite = White[!(White$Subject %in% badsubs2),] # takes out 31 white subjects
noBSnonwhite = nonWhite[!(nonWhite$Subject %in% badsubs2),] # takes out 82 nonwhite subjects
write.table(noBSall, "noBS_allData.txt", sep = "\t", row.names = F)
write.table(noBSwhite, "noBS_whiteData.txt", sep = "\t", row.names = F)
write.table(noBSnonwhite, "noBS_nonwhiteData.txt", sep = "\t", row.names = F)
nonWhite = read.delim("noBS_nonwhiteData.txt") # bad subjects taken out (answered too quickly or were distracted)
White = read.delim("noBS_whiteData.txt")
all = read.delim("noBS_allData.txt")
cor(nonWhite$UCLA_total, nonWhite$EI_total)
# correlation in nonWhite sample is .54
cor(White$UCLA_total[!(is.na(White$UCLA_total))], White$EI_total[!(is.na(White$UCLA_total))])
names(White)
cor(nonWhite$UCLA_sub, nonWhite$EI_total)
cor(White$UCLA_sub[!(is.na(White$UCLA_sub))], White$EI_total[!(is.na(White$UCLA_sub))])
cor(nonWhite$UCLA_total, nonWhite$EI_total)
# correlation in nonWhite sample is .54
cor(nonWhite$UCLA_sub, nonWhite$EI_total)
alpha(UCLAdat$UCLA_sub)
summary(alpha(UCLAdat$UCLA_sub))
names(UCLAdat)
UCLAdat[,c(22,23,24,27, 9, 10)]
head(UCLAdat[,c(22,23,24,27, 9, 10)])
head(UCLAdat[,c(22,23,24,27, 19, 20)])
alpha(UCLAdat[,c(22,23,24,27, 19, 20)])
?alpha
?alpha
detach("package:ggplot2", unload=TRUE)
alpha(UCLAdat[,c(22,23,24,27, 19, 20)])
require(magrittr)
require(dplyr)
# read in data
dat = read.delim("RawData.txt")
# add identifiers (i.e., subject numbers)
dat$Subject = 1:nrow(dat)
# how many completed fully?
length(dat$end[!(is.na(dat$end))]) # 483 completed fully
# defines items/column in each scale
UCLA = c("UCLA_1_1", "UCLA_1_2", "UCLA_1_3", "UCLA_1_4",             # UCLA loneliness
"UCLA_1_5", "UCLA_1_6", "UCLA_1_7", "UCLA_1_8",
"UCLA_1_9", "UCLA_1_10","UCLA_2_1", "UCLA_2_2",
"UCLA_2_3", "UCLA_2_4", "UCLA_2_5", "UCLA_2_6",
"UCLA_2_7", "UCLA_2_8", "UCLA_2_9", "UCLA_2_10")
SWLS = c("SLWS_1", "SLWS_2", "SLWS_3", "SLWS_4", "SLWS_5")          # Satisfaction with Life Scale
SE = c("SE_1_1", "SE_1_2", "SE_1_3", "SE_1_4",                      # Self esteem
"SE_1_5", "SE_1_6", "SE_1_7", "SE_1_8",
"SE_1_9", "SE_1_10","SE_2_1", "SE_2_2",
"SE_2_3", "SE_2_4", "SE_2_5", "SE_2_6",
"SE_2_7", "SE_2_8", "SE_2_9", "SE_2_10")
Mood = c("Mood_1", "Mood_2",  "Mood_3", "Mood_4",                   # Mood
"Mood_5", "Mood_6",  "Mood_7", "Mood_8",
"Mood_9", "Mood_10", "Mood_11","Mood_12",
"Mood_13","Mood_14", "Mood_15","Mood_16")
Disc = c("Disc_1", "Disc_2", "Disc_3", "Disc_4",                    # Perceived discrimination (general)
"Disc_5", "Disc_6", "Disc_7", "Disc_8",
"Disc_9")
DiscR = c("DiscR_1", "DiscR_2", "DiscR_3", "DiscR_4",               # Perceived discrimination (race)
"DiscR_5", "DiscR_6", "DiscR_7", "DiscR_8",
"DiscR_9")
EIS = c("EIS_1","EIS_2",                                            # Existential Isolation
"EIS_3","EIS_4",
"EIS_5","EIS_6")
WellB = c("Well_B_1", "Well_B_2", "Well_B_3", "Well_B_4",            # Well-being (Bradburn)
"Well_B_5", "Well_B_6", "Well_B_7", "Well_B_8",
"Well_B_9", "Well_B_10")
WellR = c("Rau_1", "Rem_2", "Rsa_6", "Rau_7",                        # Well-being (Ryff)
"Rem_8", "Rsa_12","Rau_13","Rem_14",
"Rsa_18","Rau_19","Rem_20","Rsa_24",
"Rau_25","Rem_26","Rsa_30","Rau_31",
"Rem_32","Rsa_36","Rau_37","Rem_38",
"Rsa_42")
# look at subjects who didn't complete fully, only take columns for questionnaire data
notComplete =
cbind(select(dat[is.na(dat$end),], Subject)) %>%
cbind(select(dat[is.na(dat$end),], one_of(UCLA))) %>%
cbind(select(dat[is.na(dat$end),], one_of(SWLS))) %>%
cbind(select(dat[is.na(dat$end),], one_of(SE))) %>%
cbind(select(dat[is.na(dat$end),], one_of(Mood))) %>%
cbind(select(dat[is.na(dat$end),], one_of(Disc))) %>%
cbind(select(dat[is.na(dat$end),], one_of(DiscR))) %>%
cbind(select(dat[is.na(dat$end),], one_of(EIS))) %>%
cbind(select(dat[is.na(dat$end),], one_of(WellB))) %>%
cbind(select(dat[is.na(dat$end),], one_of(WellR)))
# make a data frame with percentage of missing data for each subject
missing = data.frame(Subject = NULL, PercMissing = NULL)
for (i in 1:nrow(notComplete)) {
temp = notComplete[notComplete$Subject == i,]
k = sum(is.na(temp))/117
missing = rbind(missing, data.frame(Subject = i, PercMissing = k))
}
hist(missing$PercMissing, breaks = 30)
nrow(missing[missing$PercMissing > .6,])   # 20 subjects missing more than 60%
nrow(missing[missing$PercMissing > .5,])   # 24 subjects missing more than 50%
nrow(missing[missing$PercMissing > .4,])   # 28 subjects missing more than 40%
badSubs = missing[missing$PercMissing > .4,]
######################################################################################
####################### Calculate scores for each participant ########################
######################################################################################
noBS = dat[!(dat$Subject %in% badSubs$Subject),]
# UCLA Loneliness scale
# 20 items, on scale of 1 (always) to 4 (never) # mistake, should be 1 (never) to 4 (always)
# Reverse scored: 1, 5, 6, 9, 10, 15, 16, 19, 20 # would be if normal.
# Instead, rev score: 2, 3, 4, 7, 8, 11, 12, 13, 14, 17, 18
# Higher score is more lonely
UCLAdat = select(noBS, one_of(UCLA)) %>%
cbind(select(noBS, Subject))
for (i in unique(UCLAdat$Subject)) {
UCLAdat$UCLA_1_2.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_1_2[UCLAdat$Subject == i]
UCLAdat$UCLA_1_3.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_1_3[UCLAdat$Subject == i]
UCLAdat$UCLA_1_4.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_1_4[UCLAdat$Subject == i]
UCLAdat$UCLA_1_7.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_1_7[UCLAdat$Subject == i]
UCLAdat$UCLA_1_8.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_1_8[UCLAdat$Subject == i]
UCLAdat$UCLA_2_1.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_2_1[UCLAdat$Subject == i]
UCLAdat$UCLA_2_2.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_2_2[UCLAdat$Subject == i]
UCLAdat$UCLA_2_3.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_2_3[UCLAdat$Subject == i]
UCLAdat$UCLA_2_4.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_2_4[UCLAdat$Subject == i]
UCLAdat$UCLA_2_7.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_2_7[UCLAdat$Subject == i]
UCLAdat$UCLA_2_8.rev[UCLAdat$Subject == i] = 5 - UCLAdat$UCLA_2_8[UCLAdat$Subject == i]
}
# creates UCLA score by averaging across all 20 items (including reversed scored items)
UCLAdat = mutate(UCLAdat, UCLA_total =
(UCLA_1_1 + UCLA_1_2.rev + UCLA_1_3.rev + UCLA_1_4.rev +
UCLA_1_5 + UCLA_1_6 + UCLA_1_7.rev + UCLA_1_8.rev +
UCLA_1_9 + UCLA_1_10 + UCLA_2_1.rev + UCLA_2_2.rev +
UCLA_2_3.rev + UCLA_2_4.rev + UCLA_2_5 + UCLA_2_6 +
UCLA_2_7.rev + UCLA_2_8.rev + UCLA_2_9 + UCLA_2_10)/20)
# histogram shows scores normally distributed
hist(UCLAdat$UCLA_total)
# create subscale just for interpersonal loneliness items
UCLAdat = mutate(UCLAdat, UCLA_sub = (UCLA_1_2.rev + UCLA_1_3.rev + UCLA_1_4.rev +
UCLA_2_1.rev + UCLA_2_9 + UCLA_2_10)/6)
# histogram shows scores normally distributed
hist(UCLAdat$UCLA_sub, breaks = 30)
alpha(UCLAdat[,c(22,23,24,27, 19, 20)])
?alpha
??alpha
library("psych", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
alpha(UCLAdat[,c(22,23,24,27, 19, 20)])
alpha(UCLAdat$UCLA_sub)
names(UCLAdat)
alpha(UCLAdat[,1:20])
names(UCLAdat)
alpha(UCLAdat[,c(22:32,1, 5, 6, 9, 10, 15, 16, 19, 20)])
require(Hmisc)
require(dplyr)
# investigating relationships between UCLA items and EI
# first looks at correlations between UCLA items and EI_total
# then factor analysis with UCLA items and EI items included
# each done separately for each sample
nonWhite = read.delim("noBS_nonwhiteData.txt") # bad subjects taken out (answered too quickly or were distracted)
White = read.delim("noBS_whiteData.txt")
all = read.delim("noBS_allData.txt")
cor(nonWhite$UCLA_total, nonWhite$EI_total)
# correlation in nonWhite sample is .54
cor(nonWhite$UCLA_sub, nonWhite$EI_total)
# correlation with UCLA subscale (interpersonal loneliness items) is .42
cor(White$UCLA_total[!(is.na(White$UCLA_total))], White$EI_total[!(is.na(White$UCLA_total))])
# correlation in White sample is .62
cor(White$UCLA_sub[!(is.na(White$UCLA_sub))], White$EI_total[!(is.na(White$UCLA_sub))])
# correlation with UCLA subscale is .49
datNW = select(nonWhite, starts_with("UCLA")) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_total) %>%
cbind(nonWhite$EI_total)
correlNW = cor(datNW)
sort(correlNW[,21])
datW = select(White, starts_with("UCLA")) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_total) %>%
cbind(White$EI_total)
datW =  datW[!(is.na(datW$UCLA_1_7)),]
correlW = cor(datW)
sort(correlW[,21])
################ Factor analysis #######################
# for nonWhite sample
datNW2 = select(nonWhite, starts_with("UCLA")) %>%
cbind(select(nonWhite, starts_with("EIS"))) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_total,
-EIS_1,
-EIS_2,
-EIS_3,
-EIS_6)
# Maximum Likelihood Factor Analysis
# entering raw data and extracting 2 factors,
# with oblique (promax) rotation
fitNW <- factanal(datNW2, 2, rotation="promax")
print(fitNW, digits=2, cutoff=.3, sort=TRUE)
# for White sample
datW2 = select(White, starts_with("UCLA")) %>%
cbind(select(White, starts_with("EIS"))) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_total,
-EIS_1,
-EIS_2,
-EIS_3,
-EIS_6)
datW2 =  datW2[!(is.na(datW2$UCLA_1_7)),]
# Maximum Likelihood Factor Analysis
# entering raw data and extracting 2 factors,
# with oblique (promax) rotation
fitW <- factanal(datW2, 6, rotation="promax")
print(fitW, digits=2, cutoff=.3, sort=TRUE)
head(datNW2)
datNW2 = select(nonWhite, starts_with("UCLA")) %>%
cbind(select(nonWhite, starts_with("EIS"))) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_sub,
-UCLA_total,
-EIS_1,
-EIS_2,
-EIS_3,
-EIS_6)
fitNW <- factanal(datNW2, 2, rotation="promax")
print(fitNW, digits=2, cutoff=.3, sort=TRUE)
datW2 = select(White, starts_with("UCLA")) %>%
cbind(select(White, starts_with("EIS"))) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_sub
-UCLA_total,
-EIS_1,
-EIS_2,
-EIS_3,
-EIS_6)
datW2 =  datW2[!(is.na(datW2$UCLA_1_7)),]
fitW <- factanal(datW2, 6, rotation="promax")
print(fitW, digits=2, cutoff=.3, sort=TRUE)
head(datW2)
datW2 = select(White, starts_with("UCLA")) %>%
cbind(select(White, starts_with("EIS"))) %>%
select(-UCLA_1_2,
-UCLA_1_3,
-UCLA_1_4,
-UCLA_1_7,
-UCLA_1_8,
-UCLA_2_1,
-UCLA_2_2,
-UCLA_2_3,
-UCLA_2_4,
-UCLA_2_7,
-UCLA_2_8,
-UCLA_sub,
-UCLA_total,
-EIS_1,
-EIS_2,
-EIS_3,
-EIS_6)
datW2 =  datW2[!(is.na(datW2$UCLA_1_7)),]
fitW <- factanal(datW2, 6, rotation="promax")
print(fitW, digits=2, cutoff=.3, sort=TRUE)
fitW <- factanal(datW2, 2, rotation="promax")
print(fitW, digits=2, cutoff=.3, sort=TRUE)
head(datW)
select(datW, -UCLA_sub, -White$EI_total)
dim(datW)
names(datW)
datW[,1:20]
fitW_UCLA <- factanal(datW[,1:20], 2, rotation="promax")
print(fitW_UCLA, digits=2, cutoff=.3, sort=TRUE)
fitNW_UCLA <- factanal(datNW[,1:20], 2, rotation="promax")
print(fitNW_UCLA, digits=2, cutoff=.3, sort=TRUE)
fitNW_UCLA <- factanal(datNW[,1:20], 2, rotation="promax")
print(fitNW_UCLA, digits=2, cutoff=.3, sort=TRUE)
fitW_UCLA <- factanal(datW[,1:20], 2, rotation="promax")
print(fitW_UCLA, digits=2, cutoff=.3, sort=TRUE)
correlW = cor(datW)
correlW
names(datW)
sub = datW[,c(10:12,15,8:9)]
names(sub)
cor(sub)
sink("UCLA subscale interitem correlations")
cor(sub)
sink()
sort(correlW[,21])
sink("UCLA subscale interitem correlations.txt")
cor(sub)
sink()
pdf("UCLA subscale interitem correlations.txt", cor(sub))
cor(sub)
